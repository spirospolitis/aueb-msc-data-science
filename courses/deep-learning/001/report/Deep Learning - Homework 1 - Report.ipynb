{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUEB M.Sc. in Data Science\n",
    "\n",
    "- Course: **Deep Learning**\n",
    "\n",
    "- Semester: Spring 2020\n",
    "\n",
    "- Instructor: Prof. P Malakasiotis\n",
    "\n",
    "- Author: S. Politis (p3351814)\n",
    "\n",
    "- Homework: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework description (as given by instructor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit a report (max. 5 pages, PDF format) for the following machine learning projects that follow. Explain briefly in the report the architectures that you used, how they were trained, tuned, etc. Describe challenges and problems and how they were addressed. Present in the report your experimental results and demos (e.g., screenshots) showing how your code works. Do not include code in the report, but include a link to a shared folder or repository (e.g. in Dropbox, GitHub, Bitbucket) containing your code. The project will contribute 30% to the final grade.\n",
    "\n",
    "Given an image of a fashion item, build a deep learning model that recognizes the fashion item. You must use at least 2 different architectures, one with MLPs and one with CNNs. Use the Fashion-MNIST dataset to train and evaluate your models. More information about the task and the dataset can be found at https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scope of the assignment is to lead the student to a firm understanding of key tasks related to creating, training and evaluating the performance of some neural network architectures, specifically *MLP*s and *CNN*s, for the task of image classification. The assignment is not designed with the the end goal to produce the best classifier, rather to allow the student to demonstrate techniques to tweak the performance of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this goal in mind, the assignment will focus on the following tasks:\n",
    "\n",
    "- Specifying the task at hand: this is an essential step which, given the nature of the problem, will define its parameters, such as loss function to use.\n",
    "\n",
    "- Ingestion and preprocessing of input data so as to be in the correct input form for the neural network architectures that will be developed.\n",
    "\n",
    "- Sound, both theoretically and practically, splitting of train / dev / test sets.\n",
    "\n",
    "- Sound definition of the metrics required to assess the model performance.\n",
    "\n",
    "- Implementation and presentation of a few *MLP* and *CNN* architectures, their relative capacity, performance and possible shortcomings. Description of the weights initialization, activation functions, regularization techniques and optimization algorithm selected will also be provided and assesed.\n",
    "\n",
    "- Hyperparameter tuning for the best architecture selected, after manual implementation and assesment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning is well-known to benefit from *CUDA*-accelerated infrastructure, since matrix operations are orders of magnitude faster on GPU than CPU hardware. The development machine is equiped with an *Nvidia GTX1060 6GB RAM* GPU and the environment characteristics are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Param     \t\t\t| Value        \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "|---------\t\t\t\t|--------------\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Tensorflow version \t| 2.1.0 \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Built with CUDA \t\t| True     \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| GPU   \t\t\t\t| PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')  \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note about random seed: we have set the *Numpy* and *Tensorflow* seed so that stochasticity in repeated experimentation is removed and results are reproducible, especially when performing hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task of this assignment is to preform multiclass classification on the input set, based on the training set labels provided ($10$ in total)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documenting the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have useful abstractions, we have created the following *Python* packages:\n",
    "\n",
    "- Data: implements the functions for ingesting the input data (Fashion-MNIST images and classes)\n",
    "\n",
    "- Model: implements the classes and functions for constructing *MLP*s and *CNN*s\n",
    "\n",
    "- Evaluation: helper methods to evaluate the performance of the models\n",
    "\n",
    "- Visualization: implements all functions for drawing dataset images, classes distributions and *TensorFlow* history object values (*loss*, *val_loss*, *accuracy*, *val_accuracy* etc.) as graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we will be using the *TensorFlow functional API* to build our models, the reason being that it is more flexible for constructing neural network architectures. This flexibility is a non-issue for this assignment, however the knowledge obtained may prove valuable in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial dimensions of ingested data are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Dataset   | Value        \t|\n",
    "|---------\t|--------------\t|\n",
    "| X_train \t| (60000, 784) \t|\n",
    "| y_train \t| (60000,)     \t|\n",
    "| X_test   \t| (10000, 784)  |\n",
    "| y_test   \t| (10000,)  \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that there exist $60000$ training examples and $10000$ test examples. The data features are rolled-out in arrays of shape $28 \\times 28 = 784$, $28 \\times 28$ being the dimensions of input images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-applicable for the scope of thios assignment, as volume of examples seem to be adequate for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief exploratory data analysis follows below and focuses mainly on getting a feel of the data, as well as making sure that no class imbalance problem exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![First 40 dataset images](images/images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Train set target class distribution](images/train_set_target_class_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Test set target class distribution](images/test_set_target_class_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the distribution of classes in both the training and the test set are uniformly distributed, hence the dataset does not present a class imbalance problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel values normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of normalization is to fit the feature space to $[0, 1]$ because unscaled input variables can result in a slow or unstable learning process. Normalization was achieved simply by dividing each pixel value by $255$ (the maximum pixel value for grayscale images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into train / dev / test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset has already been split to train / test sets (*(X_train, y_train)*, *(X_test, y_test)* respectively), we shall proceed further by retaining a percentage ($0.20$) of the test data for creating a *development* set. The *development* set will be used for tuning hyperparameters of the model architectures, so as to acquire a robust model for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall also be extra careful to retain the uniform nature of the target class distribution so as not to introduce bias. To do this, we shall split the sets in a stratified fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final splitting of our sets is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Set     \t| Shape        \t|\n",
    "|---------\t|--------------\t|\n",
    "| X_train \t| (48000, 784) \t|\n",
    "| y_train \t| (48000,)     \t|\n",
    "| X_dev   \t| (12000, 784)  \t|\n",
    "| y_dev   \t| (12000,)      \t|\n",
    "| X_test  \t| (10000, 784)  \t|\n",
    "| y_test  \t| (10000,)      \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Dev set target class distribution](images/dev_set_target_class_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Test set target class distribution after splitting](images/split_test_set_target_class_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General remarks / architectural choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenting on the neural net depth, breadth and architecture (*MLP*s vs. *CNN*s), how to we know which size of network to create? A *MLP* with at least a hidden layer and a non-linearity is a universal continuous function approximation. However, creating a shallow *MLP* is trying to model the function in low vector space. Empirical observations show that deeper neural architectures work better in real problems. In practice it is often the case that 3-layer *MLP*s will outperform 2-layer *MLP*s, but going even deeper (4, 5, 6-layer) rarely helps much more. \n",
    "\n",
    "This is in stark contrast to *CNN*s for the task of image classification, where depth has been found to be an extremely important component for a good recognition system (e.g. on order of $10$ learnable layers). One argument for this observation is that images contain hierarchical structure so several layers of processing make intuitive sense for this domain.\n",
    "\n",
    "(source <a id=\"#stanford-cs231-cnns\" href=\"#stanford-cs231-cnns\"> [1]</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that model capacity is the ability of our model to optimaly represent the problem at hand. A lower capacity model with fail to fit its parameters during training time (i.e. the model will *underfit* the data), while an excesive capacity model will fail to generalize (i.e. it will *overfit* to the training instances).\n",
    "\n",
    "A good illustration of the *underfitting* / *overfitting* problem is given below. Note that the key diagnostic for estimating our model's capacity to generalize is provided by the gap in the plot of *loss* / *validation loss* values rolled out over training epochs. A succint model's (i.e. a model having just-right capacity) tell-tale graph is such that both metrics diminish in accord over training iterations and their gap is reasonably wide. We deduce the evaluation of the capacity of our model by evaluating the *error* metric on both the *training* and  *test* sets. The sweet spot of *underfiting* vs. *overfitting* occurs at the equilibrium of the *train error rate* vs. *test error rate*. In other words, **the optimal model capacity appears at the point at which the gap in the graph of both error metrics is minimized**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Illustrating the the model capacity for underfitting / just rigth / overfitting ](images/underfitting-just-right-overfitting.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image source: <a id=\"#say-no-to-overfitting\" href=\"#say-no-to-overfitting\">[2]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dealing with a multiclass classification task. For this reason, the appropriate loss function to use, regardless of network architecture (*MLP* or *CNN*), is **categorical cross-entropy** which is defined as:\n",
    "\n",
    "$$J(\\textbf{w}) = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\text{log}(\\hat{y}_i) + (1-y_i) \\text{log}(1-\\hat{y}_i) \\right]$$\n",
    "\n",
    "where:\n",
    "\n",
    "$\\textbf{w}$: the model parameters\n",
    "\n",
    "$y_{i}$: the **true** class label\n",
    "\n",
    "$\\hat{y_i}$: the **predicted** class label\n",
    "\n",
    "$N$: the number of classes\n",
    "\n",
    "Specifically, in TensorFlow terms, we shall use the built-in **sparse categorical cross-entropy** function, which provides users with the means of measuring the the loss without having to convert target variables to their one-hot representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing a weights initialization method in deep learning is critical because there is a risk that training progress will be slowed to the point at which the network fails to learn the parameters. This, in conjunction with the choice of a non-linear activation function (e.g. a *sigmoid*), happens because weights can be \"pushed\" to the activation function's extreme regions (e.g. at the far left or right of a *sigmoid* function), having the derivative approach zero, thereby leading to back-propagated drivatives also close to zero, thus impeding learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate the problem of *vanishing* and *exploding* gradients with an example. Please refer to the acompanying notebook \"*homework-001-vanishing-gradients.ipynb*\" and code for implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initially showcase the problem by simulating the initialization of weights from a random uniform distribution. In the sequel, we perform $100$ iterations of matrix multiplication to simulate the backward pass in a neural network. The results we get are as follows: \n",
    "\n",
    "- *Vanishing* gradients\n",
    "\n",
    "    - Parameters: matrices initialised in the range $[0, 0.1]$\n",
    "    \n",
    "    - Result: weights $\\text{mean} = (0.0,)$, $\\text{std} = 0.0$\n",
    "    \n",
    "\n",
    "- *Exploding* gradients\n",
    "\n",
    "    - Parameters: matrices initialised in the range $[0, 10]$\n",
    "    \n",
    "    - Result: weights $\\text{mean} = (inf,)$, $\\text{std} = nan$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sequel, we selectively showcase the problem of *vanishing* gradients with training a deep-and-thin model with the following parameters:\n",
    "    \n",
    "<pre>\n",
    "Model: \"fashion-mnist-mlp-vanishing-gradients1591214468\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_layer (InputLayer)     [(None, 784)]             0         \n",
    "_________________________________________________________________\n",
    "hidden_layer_1 (Dense)       (None, 8)                 6280      \n",
    "_________________________________________________________________\n",
    "hidden_layer_2 (Dense)       (None, 8)                 72        \n",
    "_________________________________________________________________\n",
    "hidden_layer_3 (Dense)       (None, 8)                 72        \n",
    "_________________________________________________________________\n",
    "hidden_layer_4 (Dense)       (None, 8)                 72        \n",
    "_________________________________________________________________\n",
    "hidden_layer_5 (Dense)       (None, 8)                 72        \n",
    "_________________________________________________________________\n",
    "hidden_layer_6 (Dense)       (None, 8)                 72        \n",
    "_________________________________________________________________\n",
    "output_layer (Dense)         (None, 10)                90        \n",
    "=================================================================\n",
    "Total params: 6,730\n",
    "Trainable params: 6,730\n",
    "Non-trainable params: 0\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training graph clearly showcases the problem which is evident by observing that the *loss* of the network does not diminish during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Illustrating vanishing gradients problem](images/vanishing_gradients.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current empirical practice in *CNN*s suggests that *He* initialization $w = \\text{np.random.randn(n)} \\times \\text{sqrt(2.0 / n)}$ is the best candidate, as discussed in <a id=\"#delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-lassification\" href=\"#delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-lassification\">[3]</a>. In their 2015 paper, they demonstrated that deep networks would converge much earlier if the weights initialization followed their strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linearities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of activation function is a deciding factor in neural net performance. It has been demonstrated that using the *sigmoid* as the activation function can quickly lead to a vanishing gradients problem, since "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current practice in *CNN*s suggests that *ReLU* units should be used as non-linearities, accompanied by *He* initialization $w = \\text{np.random.randn(n)} \\times \\text{sqrt(2.0 / n)}$, as discussed in <a id=\"#delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-lassification\" href=\"#delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-lassification\">[3]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output layer activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our task is a *multi-class classification problem*, the activation function of the output layer is a *softmax*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirical observation leads to the conclusion that *batch_size* affects overall training performance. A very high *batch_size* will affect model accuracy, while a very small batch_size will have a negative impact on convergence. We shall experiment with a base batch size of $32$ and in the sequel we shall tune the batch size during hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predominant method of regularization in neural net architectures is the introduction of *dropout* layers in between the hidden layers of the architecture. *Dropout* layers enforce random non-selection of weights, up to a configurable percentage of all weights it the current layer (i.e. a hyperparameter), thereby making sure that the model does not learn some parameters at random, effectively avoiding overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall experiments with *Stochastic Gradient Decent (SGD)* and *Adam*. For *SGD*, we shall also use momentum and configure it such that it is of type *Nesterov*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search / optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to classic machine learning models, one major challenge that one faces while working with deep learning is that there are lot of parameters to hyper tune. Hence it becomes important to appropriately select correct parameters so as to avoid  overfiting and underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tackle the hyperparameter space search problem, we shall use a Python package named *Talos* (https://github.com/autonomio/talos). The package provides all the mechanics for hyperparameter tuning. Hyperparameters are provided in the form of dictionary key-value pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing shallow, medium and deep MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, which is the right architecture for the task at hand? We have established that the *ReLU* / *He* pair should be employed, however what about the network depth and breadth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, we create $3$ MLPs with the following architectures / characteristics to try to answer such questions:\n",
    "    \n",
    "- A small MLP ($3$ hidden layer, $64$ units)\n",
    "\n",
    "- A medium MLP ($5$ hidden layer, $64$ units)\n",
    "\n",
    "- A large MLP ($7$ hidden layer, $64$ units)\n",
    "\n",
    "with the following architectures:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Model: \"fashion-mnist-mlp-small-he-relu-1591214680\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_layer (InputLayer)     [(None, 784)]             0         \n",
    "_________________________________________________________________\n",
    "hidden_layer_1 (Dense)       (None, 128)               100480    \n",
    "_________________________________________________________________\n",
    "output_layer (Dense)         (None, 10)                1290      \n",
    "=================================================================\n",
    "Total params: 101,770\n",
    "Trainable params: 101,770\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Model: \"fashion-mnist-mlp-medium-he-relu-1591214681\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_layer (InputLayer)     [(None, 784)]             0         \n",
    "_________________________________________________________________\n",
    "hidden_layer_1 (Dense)       (None, 128)               100480    \n",
    "_________________________________________________________________\n",
    "hidden_layer_2 (Dense)       (None, 128)               16512     \n",
    "_________________________________________________________________\n",
    "output_layer (Dense)         (None, 10)                1290      \n",
    "=================================================================\n",
    "Total params: 118,282\n",
    "Trainable params: 118,282\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Model: \"fashion-mnist-mlp-large-he-relu-1591214682\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_layer (InputLayer)     [(None, 784)]             0         \n",
    "_________________________________________________________________\n",
    "hidden_layer_1 (Dense)       (None, 128)               100480    \n",
    "_________________________________________________________________\n",
    "hidden_layer_2 (Dense)       (None, 128)               16512     \n",
    "_________________________________________________________________\n",
    "hidden_layer_3 (Dense)       (None, 128)               16512     \n",
    "_________________________________________________________________\n",
    "output_layer (Dense)         (None, 10)                1290      \n",
    "=================================================================\n",
    "Total params: 134,794\n",
    "Trainable params: 134,794\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained after training for $100$ epochs, using *SGD* as our optimizer with parameters $\\text{lr} = 0.01$ and *Nesterov momentum*,  are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |  |\n",
    "| --- | --- |\n",
    "| ![Baseline MLPs loss - val_loss](images/mlp_baseline_loss_val_loss_sgd.png) | ![Baseline MLPs accuracy - val_accuracy](images/mlp_baseline_accuracy_val_accuracy_sgd.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on the test set produces the following results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Architecture | Test loss | Test accuracy |\n",
    "| --- | --- | --- |\n",
    "| mlp_small | 1.715313 | 0.7492 |\n",
    "| **mlp_medium** | 1.638555 | **0.8236** |\n",
    "| mlp_large | 1.728768 | 0.7302 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clear winner is model **mlp_medium** which obtains the lowest *loss* / *val_loss*, highest *accuracy* as well as exhibits good properties in the trend of corresponding training curves. Visual inspection of the confusion matrix of the classifier indicates that the classifier does a decent job at getting true examples right (the diagonal of the matrix), however still misclassifies quite a few examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |  |  | \n",
    "| --- | --- | --- |\n",
    "| ![Small MLP confusion matrix](images/mlp_baseline_small_sgd_conf_matrix.png) | ![Medium MLP confusion matrix](images/mlp_baseline_medium_sgd_conf_matrix.png) | ![Large MLP confusion matrix](images/mlp_baseline_large_sgd_conf_matrix.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually improving on the baseline architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next iteration involves further measures to avoid *overfitting*, namely *regularization* and *early stopping*.\n",
    "\n",
    "Regularization is achieved by introducing *dropout* layers in the MLP architecture. *Early stopping* monitors *loss*, *val_loss* for identyfying a point in time (epoch) in which *val_loss* hasn't decreased w.r.t. previous epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |  |\n",
    "| --- | --- |\n",
    "| ![Baseline MLPs with early stopping / dropout loss - val_loss](images/mlp_baseline_loss_val_loss_sgd_early_stopping_dropout.png) | ![Baseline MLPs with early stopping / dropout accuracy - val_accuracy](images/mlp_baseline_accuracy_val_accuracy_sgd_early_stopping_dropout.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Architecture | Test loss | Test accuracy |\n",
    "| --- | --- | --- |\n",
    "| mlp_small | 1.703015 | 0.7586 |\n",
    "| **mlp_medium** | 1.605595 | **0.8549** |\n",
    "| mlp_large | 1.614829 | 0.8457 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |  |  | \n",
    "| --- | --- | --- |\n",
    "| ![Small MLP confusion matrix](images/mlp_baseline_small_sgd_early_stopping_dropout_conf_matrix.png) | ![Medium MLP confusion matrix](images/mlp_baseline_medium_sgd_early_stopping_dropout_conf_matrix.png) | ![Large MLP confusion matrix](images/mlp_baseline_large_sgd_early_stopping_dropout_conf_matrix.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell that the all models accuracy on the test set has improved significantly. The architecture previously selected, **mlp_medium**, remains the architecture of choice for the next step which involves hyper-parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning of the baseline architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the problem tractable, we explore $\\text{20%}$ ($64$ iterations) of the following hyperparameter search space:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Batch size(s): $16$, $32$ or $64$\n",
    "\n",
    "- Learning rate(s): $0.01$ or $0.001$\n",
    "\n",
    "- Dropout rate(s): $0.1$, $0.2$ or $0.3$\n",
    "\n",
    "- First layer number of units: $64$, $128$ or $256$\n",
    "\n",
    "- Second layer nuber of units\": $64$, $128$ or $256$\n",
    "  \n",
    "- Kernel initializer method(s): *He uniform*\n",
    "\n",
    "- Activation function(s): *ReLU*\n",
    "\n",
    "- Optimizer(s): *SGD* with *Nesterov momentum* ($0.9$) or *Adam*\n",
    "\n",
    "- Epochs: $100$ (with early stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the best model, found at iteration $50$, with the following characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| loss | first_layer_units | epochs | activation | dropout | \n",
    "| --- | --- | --- | --- | --- | \n",
    "| 50 | 1.929874 | 256 | 100 | <function relu at 0x00000183E52969D8> |\n",
    "\n",
    "| val_loss | optimizer | end | acc | duration | \n",
    "| --- | --- | --- | --- | --- | \n",
    "|  0.1 | 1.940557 | <tensorflow.python.keras.optimizer_v2.gradient... | 06/05/20-114906 | 0.887812 | \n",
    "\n",
    "| second_layer_units | val_acc | round_epochs | start | kernel_initializer | batch_size | learning_rate |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| 137.369504 | 128 | 0.876250 | 56 | 06/05/20-114649 | <tensorflow.python.ops.init_ops_v2.VarianceSca... | 32 | 0.001 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which yields a validation accuracy score of $0.869$ and test set accuracy at $0.86$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Convolutional neural networks* are a flavor of neural nets tailored for the task of image of performing deep learning on input data that are, usually, images. This assumption allows us to encode certain properties into the architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having exhaustively gone through the process of training different *MLP*s, we shall proceed with the creation of $3$ baseline *CNN*s with the following architectures / characteristics:\n",
    "\n",
    "- A small *CNN* ($1$ convolutional layer, $32$ filters)\n",
    "\n",
    "- A medium *CNN* ($2$ convolutional layers, $32$ / $64$ filters)\n",
    "\n",
    "- A large *CNN* ($3$ convolutional layer, $32$ / $64$ / $128$ filters)\n",
    "\n",
    "with the following architectures:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Model: \"fashion-mnist-cnn-small-relu-1591677112\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_layer (InputLayer)     [(None, 28, 28, 1)]       0         \n",
    "_________________________________________________________________\n",
    "conv_2d_layer_1 (Conv2D)     (None, 28, 28, 32)        320       \n",
    "_________________________________________________________________\n",
    "max_pool_2d_layer_1 (MaxPool (None, 14, 14, 32)        0         \n",
    "_________________________________________________________________\n",
    "flatten_layer (Flatten)      (None, 6272)              0         \n",
    "_________________________________________________________________\n",
    "output_layer (Dense)         (None, 10)                62730     \n",
    "=================================================================\n",
    "Total params: 63,050\n",
    "Trainable params: 63,050\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Model: \"fashion-mnist-cnn-medium-relu-1591677114\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_layer (InputLayer)     [(None, 28, 28, 1)]       0         \n",
    "_________________________________________________________________\n",
    "conv_2d_layer_1 (Conv2D)     (None, 28, 28, 32)        320       \n",
    "_________________________________________________________________\n",
    "max_pool_2d_layer_1 (MaxPool (None, 14, 14, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv_2d_layer_2 (Conv2D)     (None, 14, 14, 64)        18496     \n",
    "_________________________________________________________________\n",
    "max_pool_2d_layer_2 (MaxPool (None, 7, 7, 64)          0         \n",
    "_________________________________________________________________\n",
    "flatten_layer (Flatten)      (None, 3136)              0         \n",
    "_________________________________________________________________\n",
    "output_layer (Dense)         (None, 10)                31370     \n",
    "=================================================================\n",
    "Total params: 50,186\n",
    "Trainable params: 50,186\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Model: \"fashion-mnist-cnn-large-relu-1591677114\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_layer (InputLayer)     [(None, 28, 28, 1)]       0         \n",
    "_________________________________________________________________\n",
    "conv_2d_layer_1 (Conv2D)     (None, 28, 28, 32)        320       \n",
    "_________________________________________________________________\n",
    "max_pool_2d_layer_1 (MaxPool (None, 14, 14, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv_2d_layer_2 (Conv2D)     (None, 14, 14, 64)        18496     \n",
    "_________________________________________________________________\n",
    "max_pool_2d_layer_2 (MaxPool (None, 7, 7, 64)          0         \n",
    "_________________________________________________________________\n",
    "conv_2d_layer_3 (Conv2D)     (None, 7, 7, 128)         73856     \n",
    "_________________________________________________________________\n",
    "max_pool_2d_layer_3 (MaxPool (None, 4, 4, 128)         0         \n",
    "_________________________________________________________________\n",
    "conv_2d_layer_4 (Conv2D)     (None, 4, 4, 256)         295168    \n",
    "_________________________________________________________________\n",
    "max_pool_2d_layer_4 (MaxPool (None, 2, 2, 256)         0         \n",
    "_________________________________________________________________\n",
    "flatten_layer (Flatten)      (None, 1024)              0         \n",
    "_________________________________________________________________\n",
    "output_layer (Dense)         (None, 10)                10250     \n",
    "=================================================================\n",
    "Total params: 398,090\n",
    "Trainable params: 398,090\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained after training for $100$ epochs, using *SGD* as our optimizer with parameters  $\\text{lr}=0.01$ and *Nesterov momentum*, are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |  |\n",
    "| --- | --- |\n",
    "| ![Baseline CNNs loss - val_loss](images/cnn_baseline_loss_val_loss_sgd.png) | ![Baseline CNNs accuracy - val_accuracy](images/cnn_baseline_accuracy_val_accuracy_sgd.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on the test set produces the following results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Architecture | Test loss | Test accuracy |\n",
    "| --- | --- | --- |\n",
    "| cnn_small | 1.615897 | 0.8448 | \n",
    "| cnn_medium | 1.629447 | 0.8309 | \n",
    "| **cnn_large** | 1.566829 | 0.8941 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time around, it is evident that the larger capacity of a *CNN* is beneficial, as the larger architecture produces the best results on the test set and achieves $0.894$ accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also take a look at the corresponding confusion matrices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |  |  | \n",
    "| --- | --- | --- |\n",
    "| ![Small CNN confusion matrix](images/cnn_baseline_small_sgd_conf_matrix.png) | ![Medium CNN confusion matrix](images/cnn_baseline_medium_sgd_conf_matrix.png) | ![Large CNN confusion matrix](images/cnn_baseline_large_sgd_conf_matrix.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually improving on the baseline architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as with the *MLP*s our next iteration involves further measures to avoid *overfitting*, again by introducing *dropout* layers in the architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |  |\n",
    "| --- | --- |\n",
    "| ![Baseline CNNs with early stopping / dropout loss - val_loss](images/cnn_baseline_loss_val_loss_sgd_early_stopping_dropout.png) | ![Baseline CNNs with early stopping / dropout accuracy - val_accuracy](images/cnn_baseline_accuracy_val_accuracy_sgd_early_stopping_dropout.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Architecture | Test loss | Test accuracy |\n",
    "| --- | --- | --- |\n",
    "| cnn_small | 1.571237 | 0.8914 | \n",
    "| **cnn_medium** | 1.558384 | 0.9038 | \n",
    "| cnn_large | 1.576308 | 0.8841 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |  |  | \n",
    "| --- | --- | --- |\n",
    "| ![Small CNN confusion matrix](images/cnn_baseline_small_sgd_early_stopping_dropout_conf_matrix.png) | ![Medium CNN confusion matrix](images/cnn_baseline_medium_sgd_early_stopping_dropout_conf_matrix.png) | ![Large CNN confusion matrix](images/cnn_baseline_large_sgd_early_stopping_dropout_conf_matrix.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is interesting is that early stopping kicked-in at later epochs, when compared to the *MLP*s. Also, the medium-sized architecture performs better this time, obtaining ac accuracy score of $0.90$. We shall therefore continue on improving this architecture by performing hyperparameter tuning in the sequel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning of the baseline architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping hyperparameter space in check for outr current scope is a balancing exercise. It is easy for the search space to explode in the order of hundreds of thousands of iterations. Therefore, we shall limit the parameters for which to optimize in the following set:\n",
    "\n",
    "- Batch size: we shall keep a fixed $32$ batch size parameter, as obtained from the *MLP* case.\n",
    "\n",
    "- Learning rate(s): $0.01$ or $0.001$\n",
    "\n",
    "- Dropout rate(s): $0.1$, $0.2$ or $0.3$\n",
    "\n",
    "- Convolutional filters: $32$, $64$ or $128$\n",
    "\n",
    "- Convolutional kernel sizes: $3 \\times 3$ or $5 \\times 5$\n",
    "\n",
    "- Striding: $1$ or $2$ spaced\n",
    "\n",
    "- Padding: fixed to *'same'*\n",
    "\n",
    "- Dilation rate: fixed to $1$\n",
    "\n",
    "- Max-pool size: fixed to $(2, 2)$\n",
    "\n",
    "- Activation function(s): fixed to *ReLU*\n",
    "\n",
    "- Optimizer(s): *SGD* with *Nesterov momentum* ($0.9$) or *Adam*\n",
    "\n",
    "- Epochs: $100$ (with early stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, to keep the problem tractable, we explore only $\\text{10%}$ ($172$ iterations) of the previously described space. Given more time / computig resources we could, certainly, explore more possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the following best parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| learning_rate | batch_size | optimizer | end | output_activation | \n",
    "| --- | --- |  --- |  --- |  --- |  \n",
    "| 0.010 | 32 | <tensorflow.python.keras.optimizer_v2.gradient... | 06/09/20-144814 | <function relu at 0x00000286C1FC79D8> |\n",
    "\n",
    "| duration | loss | round_epochs | val_acc | first_layer_conv_dilation_rate | \n",
    "| --- | --- |  --- |  --- |  --- |  \n",
    "| 125.127403 | 0.142602 | 11 | 0.922083 | (1, 1)| \n",
    "\n",
    "| second_layer_activation | second_layer_conv_filters | start | dropout | second_layer_maxpool_strides | \n",
    "| --- | --- |  --- |  --- |  --- |  \n",
    "| relu | 64 | 06/09/20-144609 | 0.1 | (1, 1) |\n",
    "\n",
    "| first_layer_maxpool_pool_size | first_layer_conv_filters | epochs | second_layer_maxpool_padding | val_loss | \n",
    "| --- | --- |  --- |  --- |  --- |  \n",
    "| (2, 2) | 64 | 100 | same | 0.243917 |\n",
    "\n",
    "| first_layer_conv_kernel_size | first_layer_maxpool_padding | second_layer_conv_strides | second_layer_conv_kernel_size | \n",
    "| --- | --- |  --- |  --- | \n",
    "| (3, 3) | same | (1, 1) | (3, 3) | \n",
    "\n",
    "| second_layer_conv_dilation_rate | second_layer_maxpool_pool_size | acc | first_layer_conv_padding | \n",
    "| --- | --- | --- |  --- | \n",
    "| (1, 1) | (2, 2) | 0.947771 | same |\n",
    "\n",
    "| first_layer_maxpool_strides | second_layer_conv_padding | first_layer_conv_strides | first_layer_activation |\n",
    "| --- | --- |  --- |  --- | \n",
    "| (1, 1) | same | (1, 1) | relu |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which yields a validation accuracy score of $0.922$ and a test accuracy score of $0.916$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a id=\"stanford-cs231-cnns\"></a>\n",
    "[https://cs231n.github.io/neural-networks-1/] CS231n Convolutional Neural Networks for Visual Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. <a id=\"say-no-to-overfitting\"></a>[https://medium.com/@sayedathar11/multi-layered-perceptron-models-on-mnist-dataset-say-no-to-overfitting-3efa128a019c] Multi-Layered-Perceptron Models on MNIST Dataset : Say No to Overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. <a id=\"delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-lassification\"></a>\n",
    "[https://arxiv.org/abs/1502.01852] Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
