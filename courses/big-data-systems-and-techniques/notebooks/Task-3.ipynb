{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUEB M.Sc. in Data Science (part-time)\n",
    "\n",
    "- Semester: Summer 2020\n",
    "\n",
    "- Course: Big Data Systems and Techniques\n",
    "\n",
    "- Instructor: Prof. D. Arkoumanis\n",
    "\n",
    "- Author: Spiros Politis (p3351814)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - ML (15% data processing, 25% algorithm training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research *Spark* documentation and select two classification algorithms. The goal is to train classifiers to detect the category of each product using any information on the other columns (i.e. *name*, *description*, *brand*) except *category_name*, *category_code*, *category_id*.\n",
    "\n",
    "Think what parameters you should tune. Select as K whatever you think best for the problem.\n",
    "\n",
    "Write a spark program that reads the Task 2 *Parquet* file in a *DataFrame* and processes the data in order to be suitable to be input in the algorithms. \n",
    "\n",
    "Apply cross validation verbose to train the algorithm and tune the params. Select the params with maximum performance.\n",
    "\n",
    "Save the best model to *HDFS*.\n",
    "\n",
    "Run the training program in *Spark* in distributed mode.\n",
    "\n",
    "As deliverable give the execution commands, the above program, dumps of its execution in cross validation verbose and the model file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and custom code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.ml\n",
    "import pyspark.ml.classification\n",
    "import pyspark.ml.feature\n",
    "import pyspark.ml.evaluation\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../src/\")\n",
    "\n",
    "from Preprocessing.Transformers import LowercaseTransformer, RemoveHTMLTransformer, RemoveNonAlphanumericTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(model, df):\n",
    "    import pyspark.mllib.evaluation\n",
    "\n",
    "    # Make prediction\n",
    "    predictionAndTarget = model.transform(df).select(\"category_id_indexed\", \"prediction\")\n",
    "    \n",
    "    # Create both evaluators\n",
    "    metrics_binary = pyspark.mllib.evaluation.BinaryClassificationMetrics(predictionAndTarget.rdd.map(tuple))\n",
    "    metrics_multi = pyspark.mllib.evaluation.MulticlassMetrics(predictionAndTarget.rdd.map(tuple))\n",
    "\n",
    "    accuracy = metrics_multi.accuracy\n",
    "    precision = metrics_multi.precision(1.0)\n",
    "    recall = metrics_multi.recall(1.0)\n",
    "    f1_score = metrics_multi.fMeasure(1.0)\n",
    "    auc = metrics_binary.areaUnderROC\n",
    "    \n",
    "    print \"| Metric    | Value |\"\n",
    "    print \"|-----------|-------|\"\n",
    "    print \"| Accuracy  | {:.3f} |\".format(accuracy)\n",
    "    print \"| Error     | {:.3f} |\".format(1.0 - accuracy)\n",
    "    print \"| Precision | {:.3f} |\".format(precision)\n",
    "    print \"| Recall    | {:.3f} |\".format(recall)\n",
    "    print \"| F1-score  | {:.3f} |\".format(f1_score)\n",
    "    print \"| AUC       | {:.3f} |\".format(auc)\n",
    "\n",
    "    return accuracy, precision, recall, f1_score, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark version: 2.4.5\n"
     ]
    }
   ],
   "source": [
    "print \"PySpark version: {}\".format(sc.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.87 ms, sys: 806 µs, total: 3.68 ms\n",
      "Wall time: 3.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "shoes_df = spark.read.parquet(\"output/query_shoes.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform transformations on some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast category_id to double\n",
    "shoes_df = shoes_df.withColumn(\"category_id\", shoes_df[\"category_id\"].cast(\"double\"))\n",
    "\n",
    "# Required by the ML algorithms, the label column should be transformed.\n",
    "label_indexer = pyspark.ml.feature.StringIndexer(\n",
    "    inputCol = \"category_id\", \n",
    "    outputCol = \"category_id_indexed\"\n",
    ")\n",
    "\n",
    "label_indexer = label_indexer.fit(shoes_df)\n",
    "\n",
    "shoes_df = label_indexer.transform(shoes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- upc_id: string (nullable = true)\n",
      " |-- descr: string (nullable = true)\n",
      " |-- vendor_catalog_url: string (nullable = true)\n",
      " |-- buy_url: string (nullable = true)\n",
      " |-- manufacturer_name: string (nullable = true)\n",
      " |-- sale_price: decimal(38,18) (nullable = true)\n",
      " |-- retail_price: decimal(38,18) (nullable = true)\n",
      " |-- manufacturer_part_no: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- vendor_id: integer (nullable = true)\n",
      " |-- category_name: string (nullable = true)\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- category_id: double (nullable = true)\n",
      " |-- category_id_indexed: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shoes_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique category names and their distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|      category_code|count|\n",
      "+-------------------+-----+\n",
      "|     shoes-athletic| 4899|\n",
      "| mens-lace-up-shoes|12353|\n",
      "|        girls-shoes|21632|\n",
      "|mens-shoes-athletic| 7935|\n",
      "|      evening-shoes|  901|\n",
      "|         boys-shoes|15400|\n",
      "|       bridal-shoes|  848|\n",
      "+-------------------+-----+\n",
      "\n",
      "CPU times: user 3.71 ms, sys: 1.1 ms, total: 4.81 ms\n",
      "Wall time: 2.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "shoes_df.groupBy(\"category_code\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|descr                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Double strap design in GG fabric and leather with signature web detail and cozy rubber sole.;Adjustable double grip-tape hook-and-loop strap closure;GG fabric and leather upper;Rubber sole;Padded insole;Made in Italy                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "|Just because they're in the house doesn't mean their little feet stop moving! They'll be stylin' while keepin' it cozy in the Everest Pablo slipper. 100% boiled wool upper adorned with a colorful knit design. Slip-on design for easy on-and-off wear. Breathable wool lining helps keep feet dry and cool. Latex footbed with wool covering to keep little feet warm and comfy. Durable rubber outsole. Imported. Machine wash gentle, air dry. Measurements: ; Weight: 5 oz ; Circumference: 10 in ; Shaft: 5 in ; Product measurements were taken using size 33 (US 2 Little Kid), width M. Please note that measurements may vary by size.|\n",
      "|A handsome lace-up oxford is crafted with a lightweight, flexible sole for play-ready appeal. <ul> <li>Leather upper/suede lining/rubber sole.</li> <li>By Jumping Jacks; imported.</li> <li>Kids' shoes.</li> </ul>                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shoes_df.select(\"descr\").show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 81.5 ms, sys: 13.5 ms, total: 95.1 ms\n",
      "Wall time: 4.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining pipeline steps.\n",
    "lowercase_transformer = LowercaseTransformer.LowercaseTransformer(\n",
    "    column = \"descr\"\n",
    ")\n",
    "\n",
    "remove_html_transformer = RemoveHTMLTransformer.RemoveHTMLTransformer(\n",
    "    column = \"descr\", \n",
    "    sc = sc\n",
    ")\n",
    "\n",
    "remove_non_alphanumeric_transformer = RemoveNonAlphanumericTransformer.RemoveNonAlphanumericTransformer(\n",
    "    column = \"descr\"\n",
    ")\n",
    "\n",
    "# Defining the pipeline.\n",
    "preprocessing_pipeline = pyspark.ml.Pipeline(\n",
    "    stages = [\n",
    "        lowercase_transformer, \n",
    "        remove_html_transformer, \n",
    "        remove_non_alphanumeric_transformer\n",
    "    ]\n",
    ")\n",
    "\n",
    "shoes_df = preprocessing_pipeline.fit(shoes_df).transform(shoes_df)\n",
    "\n",
    "# Persisting the RDD for faster performance.\n",
    "shoes_df = shoes_df.persist(pyspark.StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|descr                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|double strap design in gg fabric and leather with signature web detail and cozy rubber sole adjustable double grip tape hook and loop strap closure gg fabric and leather upper rubber sole padded insole made in italy                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "|just because they re in the house doesn t mean their little feet stop moving they ll be stylin while keepin it cozy in the everest pablo slipper 100 boiled wool upper adorned with a colorful knit design slip on design for easy on and off wear breathable wool lining helps keep feet dry and cool latex footbed with wool covering to keep little feet warm and comfy durable rubber outsole imported machine wash gentle air dry measurements weight 5 oz circumference 10 in shaft 5 in product measurements were taken using size 33 us 2 little kid width m please note that measurements may vary by size |\n",
      "|a handsome lace up oxford is crafted with a lightweight flexible sole for play ready appeal leather upper suede lining rubber sole by jumping jacks imported kids shoes                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "CPU times: user 5.44 ms, sys: 406 µs, total: 5.84 ms\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "shoes_df.select(\"descr\").show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if RDD persitence is in effect, response time should be orders of magnitude lower than previous call because the processing graph has been executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|descr                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|double strap design in gg fabric and leather with signature web detail and cozy rubber sole adjustable double grip tape hook and loop strap closure gg fabric and leather upper rubber sole padded insole made in italy                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "|just because they re in the house doesn t mean their little feet stop moving they ll be stylin while keepin it cozy in the everest pablo slipper 100 boiled wool upper adorned with a colorful knit design slip on design for easy on and off wear breathable wool lining helps keep feet dry and cool latex footbed with wool covering to keep little feet warm and comfy durable rubber outsole imported machine wash gentle air dry measurements weight 5 oz circumference 10 in shaft 5 in product measurements were taken using size 33 us 2 little kid width m please note that measurements may vary by size |\n",
      "|a handsome lace up oxford is crafted with a lightweight flexible sole for play ready appeal leather upper suede lining rubber sole by jumping jacks imported kids shoes                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "CPU times: user 2.47 ms, sys: 0 ns, total: 2.47 ms\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "shoes_df.select(\"descr\").show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$80\\%$ - $20\\%$ train / test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_df, test_df) = shoes_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-vs-Rest with Logistic Regression pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://spark.apache.org/docs/2.2.0/ml-classification-regression.html#logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 523 ms, sys: 122 ms, total: 644 ms\n",
      "Wall time: 57.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Defining pipeline steps.\n",
    "\n",
    "one_vs_rest_log_reg_tokenizer = pyspark.ml.feature.Tokenizer(\n",
    "    inputCol = \"descr\", \n",
    "    outputCol = \"tokens\"\n",
    ")\n",
    "\n",
    "one_vs_rest_log_reg_hashing_tf = pyspark.ml.feature.HashingTF(\n",
    "    inputCol = one_vs_rest_log_reg_tokenizer.getOutputCol(), \n",
    "    outputCol = \"features\", \n",
    "    numFeatures = 5000\n",
    ")\n",
    "\n",
    "logistic_regression = pyspark.ml.classification.LogisticRegression(\n",
    "    maxIter = 200, \n",
    "    regParam = 0.01\n",
    ")\n",
    "one_vs_rest_log_reg_logistic_regression = logistic_regression.setFeaturesCol(\"features\")\n",
    "one_vs_rest_log_reg_logistic_regression = logistic_regression.setLabelCol(\"category_id_indexed\")\n",
    "\n",
    "one_vs_rest_classifier = pyspark.ml.classification.OneVsRest(\n",
    "    classifier = one_vs_rest_log_reg_logistic_regression\n",
    ")\n",
    "one_vs_rest_classifier = one_vs_rest_classifier.setFeaturesCol(\"features\")\n",
    "one_vs_rest_classifier = one_vs_rest_classifier.setLabelCol(\"category_id_indexed\")\n",
    "\n",
    "# Defining the pipline.\n",
    "one_vs_rest_log_reg_pipeline = pyspark.ml.Pipeline(\n",
    "    stages = [\n",
    "        one_vs_rest_log_reg_tokenizer, \n",
    "        one_vs_rest_log_reg_hashing_tf, \n",
    "        one_vs_rest_classifier\n",
    "    ]\n",
    ")\n",
    "\n",
    "one_vs_rest_model = one_vs_rest_log_reg_pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Metric    | Value |\n",
      "|-----------|-------|\n",
      "| Accuracy  | 0.794 |\n",
      "| Error     | 0.206 |\n",
      "| Precision | 0.758 |\n",
      "| Recall    | 0.706 |\n",
      "| F1-score  | 0.731 |\n",
      "| AUC       | 0.895 |\n"
     ]
    }
   ],
   "source": [
    "_ = classification_report(one_vs_rest_model, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://spark.apache.org/docs/2.2.0/ml-classification-regression.html#random-forest-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 187 ms, sys: 62.5 ms, total: 250 ms\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define pipeline steps\n",
    "random_forest_tokenizer = pyspark.ml.feature.Tokenizer(\n",
    "    inputCol = \"descr\", \n",
    "    outputCol = \"tokens\"\n",
    ")\n",
    "\n",
    "random_forest_hashing_tf = pyspark.ml.feature.HashingTF(\n",
    "    inputCol = random_forest_tokenizer.getOutputCol(), \n",
    "    outputCol = \"features\", \n",
    "    numFeatures = 5000\n",
    ")\n",
    "\n",
    "random_forest_classifier = pyspark.ml.classification.RandomForestClassifier(\n",
    "    labelCol = \"category_id_indexed\", \n",
    "    featuresCol = \"features\", \n",
    "    numTrees = 200\n",
    ")\n",
    "\n",
    "# Define pipeline\n",
    "random_forest_pipeline = pyspark.ml.Pipeline(\n",
    "    stages = [\n",
    "        random_forest_tokenizer, \n",
    "        random_forest_hashing_tf, \n",
    "        random_forest_classifier\n",
    "    ]\n",
    ")\n",
    "\n",
    "random_forest_model = random_forest_pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Metric    | Value |\n",
      "|-----------|-------|\n",
      "| Accuracy  | 0.474 |\n",
      "| Error     | 0.526 |\n",
      "| Precision | 0.081 |\n",
      "| Recall    | 0.954 |\n",
      "| F1-score  | 0.149 |\n",
      "| AUC       | 0.716 |\n"
     ]
    }
   ],
   "source": [
    "_ = classification_report(random_forest_model, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbose cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel\n",
    "from pyspark.sql.functions import rand\n",
    "\n",
    "class CrossValidatorVerbose(CrossValidator):\n",
    "\n",
    "    def _fit(self, dataset):\n",
    "        est = self.getOrDefault(self.estimator)\n",
    "        epm = self.getOrDefault(self.estimatorParamMaps)\n",
    "        numModels = len(epm)\n",
    "\n",
    "        eva = self.getOrDefault(self.evaluator)\n",
    "        metricName = eva.getMetricName()\n",
    "\n",
    "        nFolds = self.getOrDefault(self.numFolds)\n",
    "        seed = self.getOrDefault(self.seed)\n",
    "        h = 1.0 / nFolds\n",
    "\n",
    "        randCol = self.uid + \"_rand\"\n",
    "        df = dataset.select(\"*\", rand(seed).alias(randCol))\n",
    "        metrics = [0.0] * numModels\n",
    "\n",
    "        for i in range(nFolds):\n",
    "            foldNum = i + 1\n",
    "            print(\"Comparing models on fold %d\" % foldNum)\n",
    "\n",
    "            validateLB = i * h\n",
    "            validateUB = (i + 1) * h\n",
    "            condition = (df[randCol] >= validateLB) & (df[randCol] < validateUB)\n",
    "            validation = df.filter(condition)\n",
    "            train = df.filter(~condition)\n",
    "\n",
    "            for j in range(numModels):\n",
    "                paramMap = epm[j]\n",
    "                model = est.fit(train, paramMap)\n",
    "                # TODO: duplicate evaluator to take extra params from input\n",
    "                metric = eva.evaluate(model.transform(validation, paramMap))\n",
    "                metrics[j] += metric\n",
    "\n",
    "                avgSoFar = metrics[j] / foldNum\n",
    "                print(\"params: %s\\t%s: %f\\tavg: %f\" % (\n",
    "                    {param.name: val for (param, val) in paramMap.items()},\n",
    "                    metricName, metric, avgSoFar))\n",
    "\n",
    "        if eva.isLargerBetter():\n",
    "            bestIndex = np.argmax(metrics)\n",
    "        else:\n",
    "            bestIndex = np.argmin(metrics)\n",
    "\n",
    "        bestParams = epm[bestIndex]\n",
    "        bestModel = est.fit(dataset, bestParams)\n",
    "        avgMetrics = [m / nFolds for m in metrics]\n",
    "        bestAvg = avgMetrics[bestIndex]\n",
    "        print(\"Best model:\\nparams: %s\\t%s: %f\" % (\n",
    "            {param.name: val for (param, val) in bestParams.items()},\n",
    "            metricName, bestAvg))\n",
    "\n",
    "        return self._copyValues(CrossValidatorModel(bestModel, avgMetrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_vs_rest_log_reg_param_grid = pyspark.ml.tuning.ParamGridBuilder() \\\n",
    "    .addGrid(\n",
    "        one_vs_rest_log_reg_hashing_tf.numFeatures, \n",
    "        [100, 250, 500, 1000, 2500, 5000]\n",
    "    ) \\\n",
    "    .addGrid(\n",
    "        one_vs_rest_log_reg_logistic_regression.regParam, [0.1, 0.01]\n",
    "    ) \\\n",
    "    .build()\n",
    "\n",
    "one_vs_rest_log_reg_crossval = CrossValidatorVerbose(\n",
    "    estimator = one_vs_rest_log_reg_pipeline,\n",
    "    estimatorParamMaps = one_vs_rest_log_reg_param_grid,\n",
    "    evaluator = pyspark.ml.evaluation.MulticlassClassificationEvaluator(\n",
    "        labelCol = \"category_id_indexed\", \n",
    "        predictionCol = \"prediction\", \n",
    "        metricName = \"accuracy\"\n",
    "    ),\n",
    "    numFolds = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing models on fold 1\n",
      "params: {'regParam': 0.1, 'numFeatures': 100}\taccuracy: 0.554878\tavg: 0.554878\n",
      "params: {'regParam': 0.01, 'numFeatures': 100}\taccuracy: 0.574099\tavg: 0.574099\n",
      "params: {'regParam': 0.1, 'numFeatures': 250}\taccuracy: 0.617287\tavg: 0.617287\n",
      "params: {'regParam': 0.01, 'numFeatures': 250}\taccuracy: 0.643188\tavg: 0.643188\n",
      "params: {'regParam': 0.1, 'numFeatures': 500}\taccuracy: 0.686200\tavg: 0.686200\n",
      "params: {'regParam': 0.01, 'numFeatures': 500}\taccuracy: 0.713742\tavg: 0.713742\n",
      "params: {'regParam': 0.1, 'numFeatures': 1000}\taccuracy: 0.730735\tavg: 0.730735\n",
      "params: {'regParam': 0.01, 'numFeatures': 1000}\taccuracy: 0.756636\tavg: 0.756636\n",
      "params: {'regParam': 0.1, 'numFeatures': 2500}\taccuracy: 0.766657\tavg: 0.766657\n",
      "params: {'regParam': 0.01, 'numFeatures': 2500}\taccuracy: 0.780018\tavg: 0.780018\n",
      "params: {'regParam': 0.1, 'numFeatures': 5000}\taccuracy: 0.781072\tavg: 0.781072\n",
      "params: {'regParam': 0.01, 'numFeatures': 5000}\taccuracy: 0.791444\tavg: 0.791444\n",
      "Comparing models on fold 2\n",
      "params: {'regParam': 0.1, 'numFeatures': 100}\taccuracy: 0.557453\tavg: 0.556166\n",
      "params: {'regParam': 0.01, 'numFeatures': 100}\taccuracy: 0.578991\tavg: 0.576545\n",
      "params: {'regParam': 0.1, 'numFeatures': 250}\taccuracy: 0.622418\tavg: 0.619852\n",
      "params: {'regParam': 0.01, 'numFeatures': 250}\taccuracy: 0.653932\tavg: 0.648560\n",
      "params: {'regParam': 0.1, 'numFeatures': 500}\taccuracy: 0.684214\tavg: 0.685207\n",
      "params: {'regParam': 0.01, 'numFeatures': 500}\taccuracy: 0.712617\tavg: 0.713179\n",
      "params: {'regParam': 0.1, 'numFeatures': 1000}\taccuracy: 0.730575\tavg: 0.730655\n",
      "params: {'regParam': 0.01, 'numFeatures': 1000}\taccuracy: 0.756162\tavg: 0.756399\n",
      "params: {'regParam': 0.1, 'numFeatures': 2500}\taccuracy: 0.763439\tavg: 0.765048\n",
      "params: {'regParam': 0.01, 'numFeatures': 2500}\taccuracy: 0.784331\tavg: 0.782174\n",
      "params: {'regParam': 0.1, 'numFeatures': 5000}\taccuracy: 0.780927\tavg: 0.781000\n",
      "params: {'regParam': 0.01, 'numFeatures': 5000}\taccuracy: 0.792899\tavg: 0.792172\n",
      "Comparing models on fold 3\n",
      "params: {'regParam': 0.1, 'numFeatures': 100}\taccuracy: 0.552418\tavg: 0.554917\n",
      "params: {'regParam': 0.01, 'numFeatures': 100}\taccuracy: 0.579293\tavg: 0.577461\n",
      "params: {'regParam': 0.1, 'numFeatures': 250}\taccuracy: 0.620434\tavg: 0.620046\n",
      "params: {'regParam': 0.01, 'numFeatures': 250}\taccuracy: 0.650743\tavg: 0.649288\n",
      "params: {'regParam': 0.1, 'numFeatures': 500}\taccuracy: 0.687622\tavg: 0.686012\n",
      "params: {'regParam': 0.01, 'numFeatures': 500}\taccuracy: 0.715444\tavg: 0.713934\n",
      "params: {'regParam': 0.1, 'numFeatures': 1000}\taccuracy: 0.730302\tavg: 0.730538\n",
      "params: {'regParam': 0.01, 'numFeatures': 1000}\taccuracy: 0.759249\tavg: 0.757349\n",
      "params: {'regParam': 0.1, 'numFeatures': 2500}\taccuracy: 0.761617\tavg: 0.763904\n",
      "params: {'regParam': 0.01, 'numFeatures': 2500}\taccuracy: 0.779317\tavg: 0.781222\n",
      "params: {'regParam': 0.1, 'numFeatures': 5000}\taccuracy: 0.777304\tavg: 0.779768\n",
      "params: {'regParam': 0.01, 'numFeatures': 5000}\taccuracy: 0.789972\tavg: 0.791439\n",
      "Best model:\n",
      "params: {'regParam': 0.01, 'numFeatures': 5000}\taccuracy: 0.791439\n",
      "CPU times: user 34.9 s, sys: 12.2 s, total: 47.1 s\n",
      "Wall time: 36min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "one_vs_rest_log_reg_crossval = one_vs_rest_log_reg_crossval.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Metric    | Value |\n",
      "|-----------|-------|\n",
      "| Accuracy  | 0.794 |\n",
      "| Error     | 0.206 |\n",
      "| Precision | 0.758 |\n",
      "| Recall    | 0.706 |\n",
      "| F1-score  | 0.731 |\n",
      "| AUC       | 0.895 |\n"
     ]
    }
   ],
   "source": [
    "_ = classification_report(one_vs_rest_log_reg_crossval.bestModel, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params: {'regParam': 0.01, 'numFeatures': 5000}\taccuracy: 0.792899\tavg: 0.792172"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading the model (for verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_vs_rest_log_reg_crossval.bestModel.write().overwrite().save(\"output/one_vs_rest_log_reg.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = pyspark.ml.pipeline.PipelineModel.load(\"output/one_vs_rest_log_reg.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Metric    | Value |\n",
      "|-----------|-------|\n",
      "| Accuracy  | 0.794 |\n",
      "| Error     | 0.206 |\n",
      "| Precision | 0.758 |\n",
      "| Recall    | 0.706 |\n",
      "| F1-score  | 0.731 |\n",
      "| AUC       | 0.895 |\n"
     ]
    }
   ],
   "source": [
    "_ = classification_report(saved_model, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
