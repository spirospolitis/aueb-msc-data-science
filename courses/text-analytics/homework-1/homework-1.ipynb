{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUEB M.Sc. in Data Science (part-time)\n",
    "\n",
    "**Course**: Text Analytics\n",
    "\n",
    "**Semester**: Spring 2018\n",
    "\n",
    "**1st homework**: Language models\n",
    "\n",
    "**Team members**:\n",
    "\n",
    "- Alexandros Kaplanis (https://github.com/AlexcapFF/)\n",
    "- Spiros Politis\n",
    "- Manos Proimakis (https://github.com/manosprom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Implement (in any programming language) a bigram and a trigram language model for word sequences (e.g., sentences), using Laplace smoothing or optionally (much better in practice) Kneser-Ney smoothing. Train your models on a training subset of a corpus (e.g., from the English part of Europarl). Include in the vocabulary only words that occur, e.g. at least 10 times in the training subset; use the same vocabulary in the bigram and trigram models. Replace all out-of-vocabular (OOV) words (in the training, development, test subsets) by a special token \\*UNK\\*. Assume that each sentence starts with the pseudo-token \\*start\\* (or the pseudo-tokens \\*start1\\*, \\*start2\\* for the trigram model) and ends with \\*end\\*.\n",
    "\n",
    "(ii) Check the log-probabilities that your trained models return when given (correct) sentences from the test subset vs. (incorrect) sentences of the same length (in words) consisting of randomly selected vocabulary words.\n",
    "\n",
    "(iii) Estimate the language cross-entropy and perplexity of your models on the test subset of the corpus, treating the entire test subset as a single sequence, with \\*start\\* (or \\*start1\\*, \\*start2\\*) at the beginning of each sentence, and \\*end\\* at the end of each sentence. Do not include probabilities of the form P(\\*start\\*|…) (or P(\\*start1\\*|…) or P(\\*start2\\*|…)) in the computation of perplexity, but include probabilities of the form P(\\*end\\*|…).\n",
    "\n",
    "(iv) Optionally combine your two models using linear interpolation and check if the combined model performs better.\n",
    "\n",
    "You are allowed to use NLTK (http://www.nltk.org/) or other tools for sentence splitting, tokenization, and counting n-grams, but otherwise you should write your own code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/manos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Ingest first N lines of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    with open(filepath) as document:\n",
    "        content = document.read()\n",
    "    return content\n",
    "\n",
    "def load_file_part(filepath, n_lines_to_read = 100):\n",
    "    with open(filepath) as document:\n",
    "        content = \"\" . join(list([next(document) for x in range(n_lines_to_read)]))\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "filename = \"europarl-v7.el-en.en\"\n",
    "filepath = Path(\"data/\" + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest the corpus as sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting sentences\n",
    "\n",
    "From here on, we shall create the training dev and test sets with a percent. It would essentially be the same as getting a percent of lines on text, however doing that would leave some sentences incomplete.\n",
    "\n",
    "It would propably be better to get complete sentences and the train the models based on the words in this part.\n",
    "\n",
    "Therefore, we will first split the corpus into sentences, take a percent of these complete sentences and rejoin them so we will end up with 2 parts of the corpus based on the percentage we have declared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(corpus, percent = 0.5, shuffle = False):\n",
    "    from nltk.util import ngrams\n",
    "    from nltk import sent_tokenize\n",
    "\n",
    "    sentences = sent_tokenize(corpus)\n",
    "    \n",
    "    if(shuffle):\n",
    "        import random\n",
    "        random.shuffle(sentences)\n",
    "\n",
    "    size = len(sentences);\n",
    "\n",
    "    set_1 = sentences[:int(size * percent)]\n",
    "    set_2 = sentences[int(size * percent):]\n",
    "    return \" \".join(set_1), \" \".join(set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_1:  resumption of the session\n",
      "i declare resumed the session of the european parliament adjourned on friday 17 december 1999, and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period. although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful. you have requested a debate on this subject in the course of the next few days, during this part-session. in the meantime, i should like to observe a minute' s silence, as a number of members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the european union.\n",
      "\n",
      "test_set_1:  please rise, then, for this minute' s silence. (the house rose and observed a minute' s silence)\n",
      "madam president, on a point of order. you will be aware from the press and television that there have been a number of bomb explosions and killings in sri lanka. one of the people assassinated very recently in sri lanka was mr kumar ponnambalam, who had visited the european parliament just a few months ago.\n",
      "\n",
      "train_set_2:  (the house rose and observed a minute' s silence)\n",
      "madam president, on a point of order. in the meantime, i should like to observe a minute' s silence, as a number of members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the european union. although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful. you will be aware from the press and television that there have been a number of bomb explosions and killings in sri lanka.\n",
      "\n",
      "test_set_2:  please rise, then, for this minute' s silence. you have requested a debate on this subject in the course of the next few days, during this part-session. resumption of the session\n",
      "i declare resumed the session of the european parliament adjourned on friday 17 december 1999, and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period. one of the people assassinated very recently in sri lanka was mr kumar ponnambalam, who had visited the european parliament just a few months ago.\n"
     ]
    }
   ],
   "source": [
    "## Testing the train_test_split\n",
    "\n",
    "corpus_test = load_file_part(filepath, 10).lower()\n",
    "test_splitting_train_1, test_splitting_test_1 = split(corpus_test, 0.5, shuffle = False)\n",
    "print(\"train_set_1: \", test_splitting_train_1)\n",
    "print()\n",
    "print(\"test_set_1: \", test_splitting_test_1)\n",
    "\n",
    "print()\n",
    "test_splitting_train_1, test_splitting_test_1 = split(corpus_test, 0.5, shuffle = True)\n",
    "print(\"train_set_2: \", test_splitting_train_1)\n",
    "print()\n",
    "print(\"test_set_2: \", test_splitting_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding generation\n",
    "\n",
    "Adds padding around a sentence with index option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencePadding(object):\n",
    "    def __init__(self, pad_word_start = None, pad_word_end = None):\n",
    "        self.pad_word_start = pad_word_start\n",
    "        self.pad_word_end = pad_word_end\n",
    "        \n",
    "    def _wrap_with_asterisk(self, word, times = None):\n",
    "        return \"*\" + word + \"*\"\n",
    "\n",
    "    def _gen_pad(self, pad_word, times, index = False):\n",
    "        if pad_word is None: return []\n",
    "        return [self._wrap_with_asterisk(pad_word + str(i)) if index else self._wrap_with_asterisk(pad_word) for i in range(times)]\n",
    "\n",
    "    def add_padding(self, tokenized_sentence: list, times_start: int = 1, times_end: int = 1, indexed_start: bool = False, indexed_end: bool = False):\n",
    "        return self._gen_pad(self.pad_word_start, times_start, indexed_start) + tokenized_sentence + self._gen_pad(self.pad_word_end, times_end, indexed_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['*start*', 'the', 'test', 'sentence', 'without', 'padding', '.', '*end*']\n",
      "['*start*', '*start*', 'the', 'test', 'sentence', 'without', 'padding', '.', '*end0*', '*end1*']\n",
      "['*start0*', '*start1*', 'the', 'test', 'sentence', 'without', 'padding', '.', '*end*']\n"
     ]
    }
   ],
   "source": [
    "### Testing the padding\n",
    "test_padding = SentencePadding(pad_word_start = \"start\", pad_word_end = \"end\", )\n",
    "\n",
    "a_sentence = \"the test sentence without padding.\"\n",
    "from nltk import TweetTokenizer\n",
    "\n",
    "tweet_wt = TweetTokenizer()\n",
    "a_sentence = tweet_wt.tokenize(a_sentence)\n",
    "a_sentence_with_padding = test_padding.add_padding(a_sentence)\n",
    "print(a_sentence_with_padding)\n",
    "\n",
    "a_sentence_with_padding = test_padding.add_padding(a_sentence, times_start = 2, times_end = 2, indexed_start = False, indexed_end = True)\n",
    "print(a_sentence_with_padding)\n",
    "\n",
    "a_sentence_with_padding_based_on_exersise_requirements = test_padding.add_padding(a_sentence, times_start = 2, times_end = 1, indexed_start=True, indexed_end = False)\n",
    "print(a_sentence_with_padding_based_on_exersise_requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    def preprocess(self, corpus:str):\n",
    "        sentences = self._create_sentences(corpus)\n",
    "        sentences = [self._preprocess(sentence) for sentence in sentences]\n",
    "        return sentences\n",
    "\n",
    "    def _create_sentences(self, corpus):\n",
    "        from nltk import sent_tokenize\n",
    "        sentences = sent_tokenize(corpus)\n",
    "        return sentences\n",
    "    \n",
    "    def _preprocess(self, sentence):\n",
    "        sentence = self._normalize(sentence)\n",
    "        sentence = self._tokenize(sentence)\n",
    "        return sentence\n",
    "    \n",
    "    def _normalize(self, sentence):\n",
    "        sentence = sentence.lower()\n",
    "        sentence = sentence.strip()\n",
    "        return sentence\n",
    "    \n",
    "    def _tokenize(self, sentence):\n",
    "        from nltk.tokenize import TweetTokenizer\n",
    "        tweet_wt = TweetTokenizer()\n",
    "        sentence = tweet_wt.tokenize(sentence)\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary generation\n",
    "\n",
    "We shall generate the vocabulary of our corpus, taking into account only words that occure at least 10 times in the corpus. Otherwise, the word is replaced by the special token \\*UNK\\*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, cutoff_thresshold = 10, cutoff_replacement = \"*UNK*\"):\n",
    "        self._cutoff_thresshold = cutoff_thresshold\n",
    "        self._cutoff_replacement = cutoff_replacement\n",
    "            \n",
    "    @property\n",
    "    def counts(self):\n",
    "        return self._counts;\n",
    "    \n",
    "    @property\n",
    "    def cutoff_counts(self):\n",
    "        from collections import Counter\n",
    "        dic = {x: self._counts[x] for x in self._counts if self._counts[x] >= self._cutoff_thresshold}\n",
    "        return Counter(dic)\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return self._size\n",
    "    \n",
    "    def clean_sentence(self, tokenized_sentence:list):\n",
    "        return [word if word in self._vocabulary else self._cutoff_replacement for word in tokenized_sentence]\n",
    "    \n",
    "    @property\n",
    "    def unique(self):\n",
    "        return self._unique\n",
    "    \n",
    "    def __generate_word_counts_from_corpus(self, tokenized_sentences: list):        \n",
    "        from collections import Counter\n",
    "        word_counter = Counter()        \n",
    "        for sentence in tokenized_sentences:\n",
    "            word_counter.update(sentence)\n",
    "        return word_counter\n",
    "    \n",
    "    def fit(self, corpus:str = None, counts = None):       \n",
    "        from nltk import sent_tokenize\n",
    "        sentences = sent_tokenize(corpus)\n",
    "        \n",
    "        from nltk import TweetTokenizer\n",
    "        tweet_wt = TweetTokenizer()\n",
    "        sentences = [tweet_wt.tokenize(sent) for sent in sentences]\n",
    "        \n",
    "        from nltk.lm import Vocabulary\n",
    "        if(sentences is not None):\n",
    "            counts = self.__generate_word_counts_from_corpus(sentences)\n",
    "        \n",
    "        if (counts is None):\n",
    "            raise Exception(\"Invalid arguments exception\")\n",
    "        \n",
    "        self._counts = counts;\n",
    "        self._vocabulary = Vocabulary(\n",
    "            counts = self.counts,\n",
    "            unk_cutoff = self._cutoff_thresshold,\n",
    "            unk_label = self._cutoff_replacement\n",
    "        )\n",
    "        \n",
    "        self._unique = list(self._vocabulary)\n",
    "        self._size = len(self._unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', '*UNK*', '*UNK*', '*UNK*']\n",
      "Counter({'the': 17, ',': 14, 'of': 12, 'a': 11, '.': 8, 'in': 7, 'you': 5, \"'\": 5, 'on': 4, 'and': 4, 'have': 4, 'i': 3, 'european': 3, 'to': 3, 'that': 3, 'number': 3, 'this': 3, 'minute': 3, 's': 3, 'silence': 3, 'session': 2, 'parliament': 2, 'like': 2, 'as': 2, 'will': 2, 'people': 2, 'countries': 2, 'requested': 2, 'few': 2, 'sri': 2, 'lanka': 2, 'resumption': 1, 'declare': 1, 'resumed': 1, 'adjourned': 1, 'friday': 1, '17': 1, 'december': 1, '1999': 1, 'would': 1, 'once': 1, 'again': 1, 'wish': 1, 'happy': 1, 'new': 1, 'year': 1, 'hope': 1, 'enjoyed': 1, 'pleasant': 1, 'festive': 1, 'period': 1, 'although': 1, 'seen': 1, 'dreaded': 1, 'millennium': 1, 'bug': 1, 'failed': 1, 'materialise': 1, 'still': 1, 'suffered': 1, 'series': 1, 'natural': 1, 'disasters': 1, 'truly': 1, 'were': 1, 'dreadful': 1, 'debate': 1, 'subject': 1, 'course': 1, 'next': 1, 'days': 1, 'during': 1, 'part-session': 1, 'meantime': 1, 'should': 1, 'observe': 1, 'members': 1, 'behalf': 1, 'all': 1, 'victims': 1, 'concerned': 1, 'particularly': 1, 'those': 1, 'terrible': 1, 'storms': 1, 'various': 1, 'union': 1, 'please': 1, 'rise': 1, 'then': 1, 'for': 1, '(': 1, 'house': 1, 'rose': 1, 'observed': 1, ')': 1, 'madam': 1, 'president': 1, 'point': 1, 'order': 1, 'be': 1, 'aware': 1, 'from': 1, 'press': 1, 'television': 1, 'there': 1, 'been': 1, 'bomb': 1, 'explosions': 1, 'killings': 1, 'one': 1, 'assassinated': 1, 'very': 1, 'recently': 1, 'was': 1, 'mr': 1, 'kumar': 1, 'ponnambalam': 1, 'who': 1, 'had': 1, 'visited': 1, 'just': 1, 'months': 1, 'ago': 1})\n"
     ]
    }
   ],
   "source": [
    "### Testing the vocabulary\n",
    "test_vocabulary = Vocabulary(cutoff_thresshold=9, cutoff_replacement = \"*UNK*\")\n",
    "test_vocabulary.fit(corpus_test)\n",
    "\n",
    "a_sentence = \"the unkown word.\"\n",
    "from nltk import TweetTokenizer\n",
    "tweet_wt = TweetTokenizer()\n",
    "a_sentence = tweet_wt.tokenize(a_sentence)\n",
    "print(test_vocabulary.clean_sentence(a_sentence))\n",
    "print(test_vocabulary.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class LM(BaseEstimator):    \n",
    "    def __init__(self, vocabulary:Vocabulary, sentence_padding:SentencePadding = None, preprocessor:Preprocessor = None, alpha = 1, rank = 2):\n",
    "        self.__alpha = alpha\n",
    "        \n",
    "        if rank < 1:\n",
    "            raise ValueError(\"rank should be higher than 1\")\n",
    "        \n",
    "        self._rank = rank\n",
    "        self._sentence_padding = sentence_padding\n",
    "        self._vocabulary = vocabulary\n",
    "        \n",
    "        self._init_counters()\n",
    "\n",
    "    @property\n",
    "    def rank(self):\n",
    "        return self._rank\n",
    "    \n",
    "    @property\n",
    "    def counters(self):\n",
    "        return self._counters\n",
    "    \n",
    "    def fit(self, train_corpus, verbose = False):\n",
    "        self._init_counters()\n",
    "        sentences = self._create_sentences(train_corpus)\n",
    "        for sentence in sentences:\n",
    "            sentence = self._preprocess(sentence)\n",
    "            sentence = self._vocabulary.clean_sentence(sentence)\n",
    "            sentence = self._add_padding(sentence, self._rank - 1)\n",
    "            self._update_counter(self._rank, sentence)\n",
    "            self._update_counter(self._rank - 1, sentence)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, sentence, verbose = False):\n",
    "        sentence_prob, idx_count = self._calculate_sentence_prob(sentence, verbose)\n",
    "        return sentence_prob\n",
    "    \n",
    "    def score(self, test_corpus, verbose = False):\n",
    "        import math\n",
    "        sentences = self._create_sentences(test_corpus)\n",
    "        total_prob = 0\n",
    "        total_count =  0\n",
    "        for sentence in sentences:\n",
    "            sentence_prob, sentence_count = self._calculate_sentence_prob(sentence, verbose)\n",
    "            total_prob += sentence_prob\n",
    "            total_count += sentence_count\n",
    "        entropy = -total_prob / total_count\n",
    "        perplexity = math.pow(2, entropy)\n",
    "        return entropy, perplexity\n",
    "    \n",
    "    def _calculate_sentence_prob(self, sentence, verbose = False):\n",
    "        sentence = self._preprocess(sentence)\n",
    "        sentence = self._vocabulary.clean_sentence(sentence)\n",
    "        sentence = self._add_padding(sentence, self._rank)\n",
    "        \n",
    "        import math\n",
    "        sum_prob = 0\n",
    "        idx_count = 0;\n",
    "        for idx in range(self._rank - 1,len(sentence)):\n",
    "            prob = self._calculate_idx_prob(sentence, idx)\n",
    "            log_prob = math.log2(prob)\n",
    "            self._print({\"logprob\": log_prob})\n",
    "            sum_prob += log_prob\n",
    "            idx_count += 1\n",
    "        return sum_prob, idx_count\n",
    "    \n",
    "    def _calculate_idx_prob(self, sentence, idx, verbose = False):\n",
    "        self._print(\"=======================================================================\", verbose = verbose)\n",
    "        current_ngram_key = self._create_key(sentence, idx, 0)\n",
    "        previous_ngram_key = self._create_key(sentence, idx, 1)\n",
    "        current_ngram_count = self._counters.get(self._rank)[current_ngram_key]\n",
    "        previous_ngram_count = self._counters.get(self._rank - 1)[previous_ngram_key]\n",
    "\n",
    "        self._print({\"n\": (current_ngram_key, current_ngram_count), \"n-1\" : ( previous_ngram_key, previous_ngram_count) }, verbose = verbose)\n",
    "\n",
    "        prob = self._laplace_smoothing(current_ngram_count, previous_ngram_count, self.__alpha, self._vocabulary.size)\n",
    "        self._print({\"prob\": prob}, verbose = verbose)\n",
    "        self._print(\"=======================================================================\", verbose=verbose)\n",
    "        return prob\n",
    "   \n",
    "    def _laplace_smoothing(self, current_ngram_count, previous_ngram_count, alpha, vocabulary_size):\n",
    "        numerator = current_ngram_count + self.__alpha\n",
    "        denominator = previous_ngram_count + (alpha * vocabulary_size)\n",
    "        self._print({ \"numerator\": numerator, \"denominator\": denominator, \"alpha\": self.__alpha, \"vocabulary_size\": vocabulary_size })\n",
    "        return numerator / denominator\n",
    "\n",
    "    def _create_key(self, sentence, index, to):\n",
    "        key = ()\n",
    "        for i in range (self._rank - 1, to - 1, -1):\n",
    "            key = (*key, sentence[index - i])\n",
    "        return key\n",
    "    \n",
    "    def _init_counters(self):\n",
    "        from collections import Counter\n",
    "        self._counters = { key: Counter() for key in range(self._rank - 1, self._rank + 1) }\n",
    "    \n",
    "    def _create_sentences(self, corpus):\n",
    "        from nltk import sent_tokenize\n",
    "        sentences = sent_tokenize(corpus)\n",
    "        return sentences\n",
    "    \n",
    "    def _preprocess(self, sentence):\n",
    "        sentence = self._normalize(sentence)\n",
    "        sentence = self._tokenize(sentence)\n",
    "        return sentence\n",
    "    \n",
    "    def _normalize(self, sentence):\n",
    "        sentence = sentence.lower()\n",
    "        sentence = sentence.strip()\n",
    "        return sentence\n",
    "    \n",
    "    def _tokenize(self, sentence):\n",
    "        from nltk.tokenize import TweetTokenizer\n",
    "        tweet_wt = TweetTokenizer()\n",
    "        sentence = tweet_wt.tokenize(sentence)\n",
    "        return sentence\n",
    "\n",
    "    def _add_padding(self, tokenized_sentence, rank = 1):\n",
    "        return self._sentence_padding.add_padding(tokenized_sentence, times_start = rank, times_end = 1, indexed_start = True, indexed_end = False)\n",
    "    \n",
    "    def _update_counter(self, rank, sentence):\n",
    "        from nltk import ngrams\n",
    "        counts = [gram for gram in ngrams(sentence, rank)]\n",
    "        self._counters.get(rank).update(counts)\n",
    "        \n",
    "    def _print(self, *args, **kargs):\n",
    "        if kargs.get(\"verbose\", False):\n",
    "            print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest the corpus\n",
    "\n",
    "We shall use a subset of 100000 lines from the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_file_part(filepath, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate train, dev and test sets\n",
    "\n",
    "We shall split the dataset according to the 80%/20% dev/test ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = split(corpus, percent = 0.80, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The training_set will then be splitted in a train and dev set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the training set we will also take 75% as real train and the rest as temporary dev test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train, X_train_dev = split(X_train, percent = 0.80, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing the vocabulary\n",
    "trained_vocabulary = Vocabulary(cutoff_thresshold = 10, cutoff_replacement = \"*UNK*\")\n",
    "trained_vocabulary.fit(X_train_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a padding helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_padding = SentencePadding(pad_word_start = \"start\", pad_word_end = \"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences\n",
    "\n",
    "Find a sentence from the test corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He should be pleased about that, as I and many others are.\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "sentences = sent_tokenize(X_train_dev)\n",
    "random_sentence = sentences[132]\n",
    "\n",
    "print(random_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sentence of the same size from randomly selected words in the trained vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "feeling Directives whole commissioned drugs returns overlook turn secret port Beijing guarantees disappointing bold\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_nt = TweetTokenizer()\n",
    "tokenized = tweet_nt.tokenize(random_sentence)\n",
    "print(len(tokenized))\n",
    "\n",
    "import random\n",
    "t = \" \".join(random.sample(list(trained_vocabulary.cutoff_counts.keys()), 14))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_in_corpus = \"He should be pleased about that, as I and many others are.\"\n",
    "sentence_not_in_corpus = \"transposed Ms chance prepared Newton Cultural absence allegations spongiform committee drafting common up-to-date tiny\"\n",
    "sentence_with_unknowns = \"aba aeraeraer aeraee 123u unkown , coavaeery but this asdasd erqreq is araera.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Language Model\n",
    "\n",
    "Training of a bigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "bigram_lm_prob_in_corpus =  -129.73069488699372\n",
      "\n",
      "bigram_lm_prob_not_in_corpus =  -212.58445786284798\n",
      "\n",
      "bigram_lm_prob_with_unknowns =  -94.01034361863788\n",
      "\n",
      "Bigram Model Score\n",
      "Cross Entropy: 8.321\n",
      "perplexity: 319.732\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------------------------------------------------\")\n",
    "bigram_lm = LM(rank=2, vocabulary=trained_vocabulary, sentence_padding = sentence_padding).fit(X_train_train)\n",
    "bigram_lm_prob_in_corpus = bigram_lm.predict(sentence_in_corpus)\n",
    "print(\"bigram_lm_prob_in_corpus = \", bigram_lm_prob_in_corpus)\n",
    "print()\n",
    "\n",
    "bigram_lm_prob_not_in_corpus = bigram_lm.predict(sentence_not_in_corpus)\n",
    "print(\"bigram_lm_prob_not_in_corpus = \", bigram_lm_prob_not_in_corpus)\n",
    "print()\n",
    "\n",
    "bigram_lm_prob_with_unknowns = bigram_lm.predict(sentence_with_unknowns)\n",
    "print(\"bigram_lm_prob_with_unknowns = \", bigram_lm_prob_with_unknowns)\n",
    "print()\n",
    "\n",
    "bigram_lm_entropy, bigram_lm_perplexity = bigram_lm.score(X_train_dev)\n",
    "print(\"Bigram Model Score\")\n",
    "print(\"Cross Entropy: {0:.3f}\".format(bigram_lm_entropy))\n",
    "print(\"perplexity: {0:.3f}\".format(bigram_lm_perplexity))\n",
    "print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of a trigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "trigram_lm_prob_in_corpus =  -173.90599072867533\n",
      "\n",
      "trigram_lm_prob_not_in_corpus =  -209.08703916667608\n",
      "\n",
      "trigram_lm_prob_with_unknowns =  -125.79722934411396\n",
      "\n",
      "Trigram Model Score\n",
      "Cross Entropy: 10.654\n",
      "perplexity: 1610.980\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------------------------------------------------\")\n",
    "trigram_lm = LM(rank=3, vocabulary=trained_vocabulary, sentence_padding = sentence_padding).fit(X_train_train)\n",
    "trigram_lm_prob_in_corpus = trigram_lm.predict(sentence_in_corpus)\n",
    "print(\"trigram_lm_prob_in_corpus = \", trigram_lm_prob_in_corpus)\n",
    "print()\n",
    "\n",
    "trigram_lm_prob_not_in_corpus = trigram_lm.predict(sentence_not_in_corpus)\n",
    "print(\"trigram_lm_prob_not_in_corpus = \", trigram_lm_prob_not_in_corpus)\n",
    "print()\n",
    "\n",
    "trigram_lm_prob_with_unknowns = trigram_lm.predict(sentence_with_unknowns)\n",
    "print(\"trigram_lm_prob_with_unknowns = \", trigram_lm_prob_with_unknowns)\n",
    "print()\n",
    "\n",
    "trigram_lm_entropy, trigram_lm_perplexity = trigram_lm.score(X_train_dev)\n",
    "print(\"Trigram Model Score\")\n",
    "print(\"Cross Entropy: {0:.3f}\".format(trigram_lm_entropy))\n",
    "print(\"perplexity: {0:.3f}\".format(trigram_lm_perplexity))\n",
    "print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolated Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterpolatedLM(object):\n",
    "    def __init__(self, model1 : LM, model2: LM, rank = 2, lamda : float = 0):\n",
    "        self.__model1 = model1\n",
    "        self.__model2 = model2\n",
    "        self.__lamda = lamda\n",
    "        \n",
    "    def fit(self, train_corpus):\n",
    "        self.__model1.fit(train_corpus)\n",
    "        self.__model2.fit(train_corpus)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, sentence, verbose=False):\n",
    "        prob_count_model_1 = self.__model1.predict(sentence, verbose)\n",
    "        prob_count_model_2 = self.__model2.predict(sentence, verbose)\n",
    "        prob = (self.__lamda * prob_count_model_2 + (1 - self.__lamda) * prob_count_model_1)\n",
    "        return prob\n",
    "    \n",
    "    def score(self, test_corpus, verbose=False):\n",
    "        import math\n",
    "        sentences = self._create_sentences(test_corpus)\n",
    "\n",
    "        total_prob = 0\n",
    "        total_count =  0\n",
    "        for sentence in sentences:\n",
    "            prob_count_model_1, idx_count_model_1 = self.__model1._calculate_sentence_prob(sentence, verbose)\n",
    "            prob_count_model_2, idx_count_model_2 = self.__model2._calculate_sentence_prob(sentence, verbose)\n",
    "            prob = (self.__lamda * prob_count_model_2 + (1 - self.__lamda) * prob_count_model_1)\n",
    "            total_prob += prob\n",
    "            total_count += idx_count_model_2\n",
    "        entropy = -total_prob / total_count\n",
    "        perplexity = math.pow(2,entropy)\n",
    "        return entropy, perplexity\n",
    "        \n",
    "    def _create_sentences(self, corpus):\n",
    "        from nltk import sent_tokenize\n",
    "        sentences = sent_tokenize(corpus)\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_lm = LM(rank=2, vocabulary=trained_vocabulary, sentence_padding = sentence_padding).fit(X_train_train)\n",
    "trigram_lm = LM(rank=3, vocabulary=trained_vocabulary, sentence_padding = sentence_padding).fit(X_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolated_lm_prob_in_corpus =  -151.81834280783454\n",
      "\n",
      "interpolated_lm_prob_not_in_corpus =  -210.83574851476203\n",
      "\n",
      "interpolated Model Score\n",
      "Cross Entropy: 9.487\n",
      "perplexity: 717.692\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "interpolated_lm = InterpolatedLM(model1 = bigram_lm, model2 = trigram_lm, rank = 3, lamda = 0.5)\n",
    "\n",
    "interpolated_lm_prob_in_corpus = interpolated_lm.predict(sentence_in_corpus)\n",
    "print(\"interpolated_lm_prob_in_corpus = \", interpolated_lm_prob_in_corpus)\n",
    "print()\n",
    "\n",
    "interpolated_lm_prob_not_in_corpus = interpolated_lm.predict(sentence_not_in_corpus)\n",
    "print(\"interpolated_lm_prob_not_in_corpus = \", interpolated_lm_prob_not_in_corpus)\n",
    "print()\n",
    "\n",
    "interpolated_lm_entropy, interpolated_lm_perplexity = interpolated_lm.score(X_train_dev)\n",
    "print(\"interpolated Model Score\")\n",
    "print(\"Cross Entropy: {0:.3f}\".format(interpolated_lm_entropy))\n",
    "print(\"perplexity: {0:.3f}\".format(interpolated_lm_perplexity))\n",
    "print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
